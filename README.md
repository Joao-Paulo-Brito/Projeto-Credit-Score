# ‚Äãüí≥‚Äã An√°lise preditiva de pontua√ß√£o de cr√©dito (Cr√©dit Score) 

Este √© um projeto simples de **Ci√™ncia de dados** que tem como objetivo prever o **Credit Score** de uma pessoa, definindo quais s√£o suas chances
de pagar suas d√≠vidas atrav√©s de um algoritmo de classifica√ß√£o, que nesse caso se trata do "Random Forest" da biblioteca **Sckit Learn**.

<p align="center">
  <img src="img/credit-score.png" width="600"/>
</p>

### üìå Tecnologias utilizadas:
<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" />
  <img src="https://img.shields.io/badge/Matplotlib-11557c?style=for-the-badge&logo=plotly&logoColor=white" />
  <img src="https://img.shields.io/badge/Seaborn-4C72B0?style=for-the-badge&logo=plotly&logoColor=white" />
  <img src="https://img.shields.io/badge/Scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white" />
  <img src="https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white" />
  <img src="https://img.shields.io/badge/Yellowbrick-%23F7DC6F?style=for-the-badge&logo=Yellowbrick&logoColor=black" />
</p>

---
<br>

# Objetivo do projeto

Como foi dito anteriormente, o objetivo deste projeto √© prever a classifica√ß√£o de cr√©dito de um indiv√≠duo, e para isso, foram organizadas 5 perguntas para definir
quais dados de uma pessoa tem maior influ√™ncia na sua pontua√ß√£o de cr√©dito, para identificar padr√µes e como esses aspectos podem ser usados para explicar o seu **Credit Score**.

<br>

# Coleta dos dados

A coleta dos dados foi feita no site [Kaggle](https://www.kaggle.com/) para baixar um dataset simples de [Credit Score](https://www.kaggle.com/datasets/sujithmandala/credit-score-classification-dataset) para
aplicar meus conhecimentos b√°sicos de aprendizado de m√°quina de classifica√ß√£o.

<br>

# Detalhes do dataset

De acordo com as informa√ß√µes do criador, esse dataset possui uma amostra de informa√ß√µes de mais de 100 pessoas em todo o mundo, informa√ß√µes como:

* **Age**: Idade das pessoas
  
* **Gender**: Sexo das pessoas (Masculino/Feminino)
  
* **Income**: Sal√°rio m√©dio (Moeda desconhecida, provavelmente em d√≥lares)
  
* **Education**: Grau de escolaridade
  - High School Diploma ‚Üí Ensino m√©dio completo
  - Bachelor's Degree ‚Üí Ensino superior completo (Bacharelado)
  - Master's Degree ‚Üí Mestrado
  - Doctorate ‚Üí Doutorado
  - Associate's Degree ‚Üí Grau de associado

* **Marital Status**: Estado civil (Solteiro/Casado)

* **Number of Children**: N√∫mero de filhos

* **Home Ownership**: Tipo de moradia (Casa pr√≥pria/Aluguel)

* **Credit Score**: Pontua√ß√£o de cr√©dito (Alto/M√©dio/Baixo)

<br>

# Metodologia

* **Tratamento dos dados**: Antes dos dados serem inseridos no modelo de machine learning, √© necess√°rio haver o tratamento dos dados brutos para remover poss√≠veis erros e dados incoerentes presentes no dataset, para n√£o comprometer o resultado da an√°lise feita pelo modelo.

* **Pr√©-processamento dos dados**:
  - Separa√ß√£o dos dados: Primeiramente os dados foram separados em features(x), que s√£o os dados usados para fazer a previs√£o, ou seja, todas as colunas exceto pela coluna 'Credit Score', que foi a coluna separada como um target(y), que s√£o os dados que ser√£o previstos pelo modelo. Al√©m disso, antes de haver o pr√©-processamento para o modelo ser treinado, os dados foram separados em dados de treino e teste, para que n√£o ocorra vazamento de dados ou **data lackage**.
    
  - Encoders: Para que os dados possam ser inseridos no modelo, os dados categ√≥ricos devem ser codificados e transformados em n√∫meros, sendo que os dados categ√≥ricos ordenados devem ser codificados pelo algoritmo de 'Label Encoder', que no caso s√£o os dados da coluna target(y) ou chamada de 'Credit Score'. J√° os dados categ√≥ricos n√£o ordenados, que est√£o presentes nos dados das features(x), devem ser codificados pelo algoritmo "Ohe Hot Encoder", codificando colunas como "Gender", "Income", "Education", "Material Status" e "Home Ownership".
 
* **Treinamento dos modelos**: Foram usados dois modelos de classifica√ß√£o, o modelo **Naive Bayes** e o modelo **Random Forest**, sendo que ambos os modelos tiveram um desempenho bom durante os processos, com 100% de acur√°cia, por√©m na valida√ß√£o cruzada para verificar o desempenho dos modelos, o modelo Naive Bayes teve um desempenho ligeiramente maior que o Random Forest, com 98% de acur√°ria, enquanto o Random Forest teve 94% de acur√°cia. Al√©m disso, foram feitos os gr√°ficos de matriz de confus√£o, para verificar os acertos e erros de ambos os modelos:
  - Modelo Naive Bayes:
    <p>
      <img src="graphics/Matriz-Confusao-NB.png" width="600">
    </p>

  - Modelo Random Forest:
    <p>
      <img src="graphics/Matriz-Confusao-RF.png" width="600">
    </p>

* **An√°lise da import√¢ncia das features**: Para verificar o peso das vari√°veis na previs√£o, √© preciso analisar a import√¢ncia das features(x) do modelo, ou **feature importance**, que foi feita nos dois modelos usados no projeto.
  - Modelo Naive Bayes:
    <p>
      <img src="graphics/import√¢ncia-das-features-NB.png" width="600">
    </p>
    Para verificar a import√¢ncia das features do modelo Naive Bayes, que n√£o possui uma fun√ß√£o espec√≠fica para essa an√°lise, foi usada uma fun√ß√£o chamada de "Permutation importance", que avalia a import√¢ncia de cada vari√°vel no modelo treinado, e o resultado dessa an√°lise de import√¢ncia ficou razoavelmente distribuido entre as vari√°veis, sendo as vari√°veis com maior peso sendo relacioandas ao tipo de moradia.

<br>

   - Modelo Random Forest:
    <p>
      <img src="graphics/import√¢ncia-das-features-RF.png" width="600">
    </p>
    Dessa vez, a import√¢ncia das features do modelo Random Forest foi analisada a partir de uma fun√ß√£o embutida nesse algoritmo, que √© chamada de "feature_importances_", em que para fazer a an√°lise de import√¢ncia, essa fun√ß√£o usa uma m√©trica chamada de "Import√¢ncia de Gini", que mede a redu√ß√£o m√©dia de impureza de Gini que cada vari√°vel causa ao ser usada nas splits das √°vores, quanto maior √© a import√¢ncia de Gini, mais importante √© a feature para o modelo. E nesse caso, n√£o houve tanta distruibui√ß√£o de import√¢ncia que nem no modelo Naive Bayes, no modelo Random Forest o foco principal est√° nas vari√°veis "Age" e "Income".
